{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning, Sarsa Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flow\n",
    "- define the maze\n",
    "- define theta for initial policy \n",
    "- convert theta into policy_0\n",
    "- initialize Q-function\n",
    "- define Sarsa and Q-learning\n",
    "- define play_maze function\n",
    "- main function\n",
    "- visualize V (state-value function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T02:07:15.984030Z",
     "start_time": "2019-03-29T02:07:15.979374Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T05:14:54.742804Z",
     "start_time": "2019-03-08T05:14:54.488047Z"
    }
   },
   "source": [
    "## define the maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T02:07:17.114670Z",
     "start_time": "2019-03-29T02:07:16.900549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = plt.gca()\n",
    "\n",
    "# draw red wall\n",
    "plt.plot([3, 4], [2, 2], color='red', linewidth=3)\n",
    "plt.plot([2, 2], [1, 2], color='red', linewidth=3)\n",
    "plt.plot([1, 1], [2, 4], color='red', linewidth=3)\n",
    "plt.plot([1, 2], [1, 1], color='red', linewidth=3)\n",
    "plt.plot([2, 3], [3, 3], color='red', linewidth=3)\n",
    "plt.plot([3, 3], [2, 3], color='red', linewidth=3)\n",
    "plt.plot([3, 3], [0, 1], color='red', linewidth=3)\n",
    "\n",
    "# -- describe the state number\n",
    "s_num = 0\n",
    "for j in range(4):\n",
    "    for i in range(4):\n",
    "        plt.text(i+0.5, j+0.5, 's{}'.format(s_num), size=20, ha='center')\n",
    "        s_num += 1\n",
    "        \n",
    "# -- setup the START and GOAL\n",
    "plt.text(0.5, 0.3, 'START', ha='center', fontsize=14)\n",
    "plt.text(3.5, 3.3, 'GOAL', ha='center', fontsize=14)\n",
    "\n",
    "# -- reformat size\n",
    "ax.set_xlim(0, 4)\n",
    "ax.set_ylim(0, 4)\n",
    "plt.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                labelbottom=False, right=False, left=False, labelleft=False)\n",
    "\n",
    "# -- render the green circle in current state (initial state is START)\n",
    "line, = ax.plot([0.5], [0.5], marker=\"o\", color='g', markersize=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T05:14:55.493831Z",
     "start_time": "2019-03-08T05:14:55.481224Z"
    }
   },
   "source": [
    "## define theta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T02:07:17.961978Z",
     "start_time": "2019-03-29T02:07:17.953862Z"
    }
   },
   "outputs": [],
   "source": [
    "# - define the theta for initial policy by Tabler Representative\n",
    "#                 [\"UP\"  , \"RIGHT\", \"DOWN\", \"LEFT\"]\n",
    "theta = np.array([[1     , 1      , np.nan, np.nan], #s0\n",
    "                  [np.nan, 1      , np.nan, 1     ], #s1\n",
    "                  [1     , np.nan , np.nan, 1     ], #s2\n",
    "                  [1     , np.nan , np.nan, np.nan], #s3\n",
    "                  [1     , 1      , 1     , np.nan], #s4\n",
    "                  [1     , np.nan , np.nan, 1     ], #s5\n",
    "                  [1     , 1      , 1     , np.nan], #s6\n",
    "                  [np.nan, np.nan , 1     , 1     ], #s7\n",
    "                  [1     , np.nan , 1     , np.nan], #s8\n",
    "                  [1     , 1      , 1     , np.nan], #s9\n",
    "                  [np.nan, np.nan , 1     , 1     ], #s10\n",
    "                  [1     , np.nan , np.nan, np.nan], #s11\n",
    "                  [np.nan, np.nan , 1     , np.nan], #s12\n",
    "                  [np.nan, 1      , 1     , np.nan], #s13\n",
    "                  [np.nan, 1      , np.nan, 1     ], #s14\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T05:14:55.874140Z",
     "start_time": "2019-03-08T05:14:55.865098Z"
    }
   },
   "source": [
    "## convert theta into Policy Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T02:07:19.232287Z",
     "start_time": "2019-03-29T02:07:19.226183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        0.5        0.         0.        ]\n",
      " [0.         0.5        0.         0.5       ]\n",
      " [0.5        0.         0.         0.5       ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.33333333 0.33333333 0.33333333 0.        ]\n",
      " [0.5        0.         0.         0.5       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.        ]\n",
      " [0.         0.         0.5        0.5       ]\n",
      " [0.5        0.         0.5        0.        ]\n",
      " [0.33333333 0.33333333 0.33333333 0.        ]\n",
      " [0.         0.         0.5        0.5       ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.5        0.5        0.        ]\n",
      " [0.         0.5        0.         0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "def convert_theta_into_pi(theta):\n",
    "    \n",
    "    i, j = theta.shape\n",
    "    pi = np.zeros((i, j))\n",
    "    for row in range(i):\n",
    "        # get probability of action\n",
    "        pi[row] = theta[row] / np.nansum(theta[row])\n",
    "        \n",
    "    pi = np.nan_to_num(pi)\n",
    "    return pi\n",
    "\n",
    "pi_0 = convert_theta_into_pi(theta)\n",
    "print(pi_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T05:14:56.158690Z",
     "start_time": "2019-03-08T05:14:56.150618Z"
    },
    "scrolled": true
   },
   "source": [
    "## initialize Q function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T02:07:21.484776Z",
     "start_time": "2019-03-29T02:07:21.479305Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07195352 0.05927843        nan        nan]\n",
      " [       nan 0.04212888        nan 0.09617763]\n",
      " [0.0852002         nan        nan 0.09433165]\n",
      " [0.02860838        nan        nan        nan]\n",
      " [0.08704304 0.09658944 0.06413937        nan]\n",
      " [0.06957655        nan        nan 0.01131479]\n",
      " [0.04635191 0.08569776 0.09127667        nan]\n",
      " [       nan        nan 0.02813562 0.05981237]\n",
      " [0.07965442        nan 0.03181835        nan]\n",
      " [0.07997931 0.00764603 0.00081551        nan]\n",
      " [       nan        nan 0.04270071 0.04403313]\n",
      " [0.01800518        nan        nan        nan]\n",
      " [       nan        nan 0.08086441        nan]\n",
      " [       nan 0.08106875 0.08304737        nan]\n",
      " [       nan 0.03668151        nan 0.06147955]]\n"
     ]
    }
   ],
   "source": [
    "i, j = pi_0.shape\n",
    "Q = np.random.rand(i, j) * theta *0.1\n",
    "# In order to avoid miss action in early exeperiments,\n",
    "# multiplying 0.1 \n",
    "\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T02:07:23.281934Z",
     "start_time": "2019-03-29T02:07:23.275362Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_next_action(s, Q, pi, epsilon) -> str:\n",
    "    # return 'UP', 'DOWN', 'RIGHT', 'LEFT'\n",
    "    \n",
    "    # epsilon-greedy\n",
    "    if np.random.rand() < epsilon:\n",
    "        next_action = np.random.choice(list(directions), p=pi[s, :])\n",
    "    else:\n",
    "        next_action = list(directions)[np.nanargmax(Q[s, :])] \n",
    "        \n",
    "    return next_action\n",
    "\n",
    "def get_s_next(s, next_a) -> int:\n",
    "    # return state num\n",
    "    \n",
    "    for idx, act in enumerate(directions):\n",
    "        if act == next_a:\n",
    "            return s + directions[act]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T02:07:23.841024Z",
     "start_time": "2019-03-29T02:07:23.838017Z"
    }
   },
   "outputs": [],
   "source": [
    "# - test\n",
    "# s = 9\n",
    "# next_a = get_next_action(s, Q, pi_0, 0.3)\n",
    "# print(\"next_action is {}\".format(next_a))\n",
    "# next_s = get_s_next(s, next_a)\n",
    "# print(\"next state is {}\".format(next_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T05:14:58.913373Z",
     "start_time": "2019-03-08T05:14:58.904912Z"
    }
   },
   "source": [
    "## define Sarsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T02:07:25.303483Z",
     "start_time": "2019-03-29T02:07:25.297909Z"
    }
   },
   "outputs": [],
   "source": [
    "def Sarsa(Q, s, a, r, s_next, a_next, eta, gamma):\n",
    "\n",
    "    a_col = action2col[a]\n",
    "    if s_next == 15:  # goal\n",
    "        Q[s, a_col] = Q[s, a_col] + eta * (r - Q[s, a_col])\n",
    "\n",
    "    else:\n",
    "        a_next_col = action2col[a_next]\n",
    "        Q[s, a_col] = Q[s, a_col] + eta * (r + gamma * Q[s_next, a_next_col] - Q[s, a_col])\n",
    "\n",
    "    return Q.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T05:14:57.808283Z",
     "start_time": "2019-03-08T05:14:57.800307Z"
    }
   },
   "source": [
    "## define Q learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T02:07:28.360837Z",
     "start_time": "2019-03-29T02:07:28.354987Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_q_learning(Q, s, a, r, s_next, eta, gamma):\n",
    "    \n",
    "    a_col = action2col[a]\n",
    "    if s_next == 15:\n",
    "        Q[s, a_col] = Q[s, a_col] + eta * (r - Q[s, a_col])\n",
    "        return Q.copy()\n",
    "    else:\n",
    "        Q[s, a_col] = Q[s, a_col] + eta * (r + gamma * np.nanmax(Q[s_next, :]) - Q[s, a_col])\n",
    "        return Q.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T02:08:04.003282Z",
     "start_time": "2019-03-29T02:08:03.995499Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def play_maze(Q, pi, epsilon, eta, gamma, update_method=\"q_learning\"):\n",
    "    # return state_action_history, updated Q function\n",
    "    s = 0\n",
    "    s_a_history = [[0, np.nan]]\n",
    "    # substitute action later\n",
    "    \n",
    "    trial_num  = 0\n",
    "    a_next = get_next_action(s, Q, pi, epsilon)\n",
    "    # selecting action\n",
    "    \n",
    "    while True:\n",
    "        # print(\"current state: {}, next action : {}\".format(s, action))\n",
    "        action = a_next \n",
    "        \n",
    "        trial_num += 1\n",
    "        \n",
    "        s_a_history[-1][1] = action\n",
    "        \n",
    "        s_next = get_s_next(s=s, next_a=action)\n",
    "       \n",
    "        s_a_history.append([s_next, np.nan])\n",
    "        \n",
    "        if s_next == 15:\n",
    "            r = 1\n",
    "            a_next = None\n",
    "        else:\n",
    "            r = 0\n",
    "            a_next = get_next_action(s_next, Q, pi, epsilon)\n",
    "        \n",
    "        if update_method == \"sarsa\":\n",
    "            Q = Sarsa(Q, s, action, r, s_next, a_next, eta, gamma)\n",
    "            \n",
    "        elif update_method == \"q_learning\":\n",
    "            Q = update_q_learning(Q, s, action, r, s_next, eta, gamma)\n",
    "        \n",
    "        if s_next == 15:\n",
    "            break\n",
    "        else:\n",
    "            s = s_next\n",
    "        \n",
    "    return s_a_history, Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T02:08:04.700629Z",
     "start_time": "2019-03-29T02:08:04.505173Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Episode: 1 ==========\n",
      "Sarsa step size in this trial is 110.\n",
      "Q-learning step size in this trial is 110.\n",
      "========== Episode: 2 ==========\n",
      "Sarsa step size in this trial is 98.\n",
      "Q-learning step size in this trial is 98.\n",
      "========== Episode: 3 ==========\n",
      "Sarsa step size in this trial is 42.\n",
      "Q-learning step size in this trial is 42.\n",
      "========== Episode: 4 ==========\n",
      "Sarsa step size in this trial is 130.\n",
      "Q-learning step size in this trial is 130.\n",
      "========== Episode: 5 ==========\n",
      "Sarsa step size in this trial is 112.\n",
      "Q-learning step size in this trial is 112.\n",
      "========== Episode: 6 ==========\n",
      "Sarsa step size in this trial is 132.\n",
      "Q-learning step size in this trial is 132.\n",
      "========== Episode: 7 ==========\n",
      "Sarsa step size in this trial is 50.\n",
      "Q-learning step size in this trial is 50.\n",
      "========== Episode: 8 ==========\n",
      "Sarsa step size in this trial is 68.\n",
      "Q-learning step size in this trial is 68.\n",
      "========== Episode: 9 ==========\n",
      "Sarsa step size in this trial is 28.\n",
      "Q-learning step size in this trial is 28.\n",
      "========== Episode: 10 ==========\n",
      "Sarsa step size in this trial is 10.\n",
      "Q-learning step size in this trial is 10.\n",
      "========== Episode: 11 ==========\n",
      "Sarsa step size in this trial is 10.\n",
      "Q-learning step size in this trial is 10.\n",
      "========== Episode: 12 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 13 ==========\n",
      "Sarsa step size in this trial is 18.\n",
      "Q-learning step size in this trial is 18.\n",
      "========== Episode: 14 ==========\n",
      "Sarsa step size in this trial is 18.\n",
      "Q-learning step size in this trial is 18.\n",
      "========== Episode: 15 ==========\n",
      "Sarsa step size in this trial is 30.\n",
      "Q-learning step size in this trial is 30.\n",
      "========== Episode: 16 ==========\n",
      "Sarsa step size in this trial is 32.\n",
      "Q-learning step size in this trial is 32.\n",
      "========== Episode: 17 ==========\n",
      "Sarsa step size in this trial is 32.\n",
      "Q-learning step size in this trial is 32.\n",
      "========== Episode: 18 ==========\n",
      "Sarsa step size in this trial is 26.\n",
      "Q-learning step size in this trial is 26.\n",
      "========== Episode: 19 ==========\n",
      "Sarsa step size in this trial is 26.\n",
      "Q-learning step size in this trial is 26.\n",
      "========== Episode: 20 ==========\n",
      "Sarsa step size in this trial is 26.\n",
      "Q-learning step size in this trial is 26.\n",
      "========== Episode: 21 ==========\n",
      "Sarsa step size in this trial is 20.\n",
      "Q-learning step size in this trial is 20.\n",
      "========== Episode: 22 ==========\n",
      "Sarsa step size in this trial is 26.\n",
      "Q-learning step size in this trial is 26.\n",
      "========== Episode: 23 ==========\n",
      "Sarsa step size in this trial is 14.\n",
      "Q-learning step size in this trial is 14.\n",
      "========== Episode: 24 ==========\n",
      "Sarsa step size in this trial is 26.\n",
      "Q-learning step size in this trial is 26.\n",
      "========== Episode: 25 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 26 ==========\n",
      "Sarsa step size in this trial is 20.\n",
      "Q-learning step size in this trial is 20.\n",
      "========== Episode: 27 ==========\n",
      "Sarsa step size in this trial is 14.\n",
      "Q-learning step size in this trial is 14.\n",
      "========== Episode: 28 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 29 ==========\n",
      "Sarsa step size in this trial is 10.\n",
      "Q-learning step size in this trial is 10.\n",
      "========== Episode: 30 ==========\n",
      "Sarsa step size in this trial is 32.\n",
      "Q-learning step size in this trial is 32.\n",
      "========== Episode: 31 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 32 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 33 ==========\n",
      "Sarsa step size in this trial is 10.\n",
      "Q-learning step size in this trial is 10.\n",
      "========== Episode: 34 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 35 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 36 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 37 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 38 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 39 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 40 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 41 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 42 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 43 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 44 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 45 ==========\n",
      "Sarsa step size in this trial is 10.\n",
      "Q-learning step size in this trial is 10.\n",
      "========== Episode: 46 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 47 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 48 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 49 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 50 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 51 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 52 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 53 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 54 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 55 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 56 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 57 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 58 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 59 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 60 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 61 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 62 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 63 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 64 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 65 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 66 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 67 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 68 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 69 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 70 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 71 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 72 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 73 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 74 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 75 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 76 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 77 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 78 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 79 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 80 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 81 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 82 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 83 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 84 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 85 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 86 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 87 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 88 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 89 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 90 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 91 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 92 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 93 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 94 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 95 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 96 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 97 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 98 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n",
      "========== Episode: 99 ==========\n",
      "Sarsa step size in this trial is 8.\n",
      "Q-learning step size in this trial is 8.\n"
     ]
    }
   ],
   "source": [
    "# - define the const\n",
    "\n",
    "eta = 0.1   # learning rate\n",
    "GAMMA = 0.9 # discount rate\n",
    "epsilon = 0.5\n",
    "continue_flg = True\n",
    "episode = 1\n",
    "max_episode = 100\n",
    "directions = {'UP'   :  4,\n",
    "              'RIGHT':  1,\n",
    "              'DOWN' : -4,\n",
    "              'LEFT' : -1\n",
    "             }\n",
    "\n",
    "action2col = { act: col for col,act in enumerate(directions) }\n",
    "i, j = pi_0.shape\n",
    "Q = np.random.rand(i, j) * theta * 0.1\n",
    "initial_Q = Q.copy()\n",
    "Q_sarsa = Q.copy()\n",
    "Q_Qlearning = Q.copy()\n",
    "# get transition V function by time step\n",
    "V_sarsa = np.nanmax(Q, axis=1).reshape(1, -1)\n",
    "V_Qlearning = np.nanmax(Q, axis=1).reshape(1, -1)\n",
    "\n",
    "while continue_flg:\n",
    "    \n",
    "    print(\"========== Episode: {} ==========\".format(episode))\n",
    "    epsilon /= 1.1\n",
    "    # more exploration in earlier experices \n",
    "    \n",
    "    s_a_history_sarsa    , new_Q_sarsa     = play_maze(Q_sarsa    , pi_0, epsilon, eta, GAMMA, update_method=\"sarsa\")\n",
    "    s_a_history_Qlearning, new_Q_Qlearning = play_maze(Q_Qlearning, pi_0, epsilon, eta, GAMMA)\n",
    "    \n",
    "    new_v_sarsa     = np.nanmax(new_Q_sarsa    , axis=1).reshape(1, -1)\n",
    "    new_v_Qlearning = np.nanmax(new_Q_Qlearning, axis=1).reshape(1, -1)\n",
    "    \n",
    "    V_sarsa     = np.append(V_sarsa    , new_v_sarsa, axis=0)\n",
    "    V_Qlearning = np.append(V_Qlearning, new_v_Qlearning, axis=0)\n",
    "    \n",
    "    Q_sarsa     = new_Q_sarsa.copy()\n",
    "    Q_Qlearning = new_Q_Qlearning.copy()\n",
    "    \n",
    "    print(\"Sarsa step size in this trial is {}.\".format(len(s_a_history_sarsa)-1))\n",
    "    print(\"Q-learning step size in this trial is {}.\".format(len(s_a_history_sarsa)-1))\n",
    "    \n",
    "    episode += 1\n",
    "    if episode >= max_episode:\n",
    "        continue_flg = False\n",
    "\n",
    "# - reformat V for visualizing\n",
    "v_16 = np.ones((100,1))\n",
    "V_sarsa = np.concatenate((V_sarsa, v_16), axis=1).reshape(-1, 4, 4)\n",
    "V_Qlearning = np.concatenate((V_Qlearning, v_16), axis=1).reshape(-1, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T02:08:09.034636Z",
     "start_time": "2019-03-29T02:08:09.031043Z"
    }
   },
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T02:08:12.493286Z",
     "start_time": "2019-03-29T02:08:12.488685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.04441648, 0.38110073,        nan,        nan],\n",
      "       [       nan, 0.46933848,        nan, 0.02043787],\n",
      "       [0.55615872,        nan,        nan, 0.04974129],\n",
      "       [0.04516881,        nan,        nan,        nan],\n",
      "       [0.04327123, 0.02682085, 0.04359952,        nan],\n",
      "       [0.0924776 ,        nan,        nan, 0.00530643],\n",
      "       [0.64017118, 0.04423951, 0.05179365,        nan],\n",
      "       [       nan,        nan, 0.01956689, 0.04901004],\n",
      "       [0.04333943,        nan, 0.04307404,        nan],\n",
      "       [0.80832949, 0.02721969, 0.03224761,        nan],\n",
      "       [       nan,        nan, 0.05387294, 0.72305547],\n",
      "       [0.01011495,        nan,        nan,        nan],\n",
      "       [       nan,        nan, 0.04323203,        nan],\n",
      "       [       nan, 0.89968623, 0.04818459,        nan],\n",
      "       [       nan, 0.99997051,        nan, 0.09992044]])\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(Q_Qlearning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the differences between q-learning and Sarsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T06:50:03.780573Z",
     "start_time": "2019-03-12T06:50:03.777728Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T06:50:05.323898Z",
     "start_time": "2019-03-12T06:50:04.663641Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(18, 5))\n",
    "\n",
    "ax2.set_title(\"Sarsa\",fontsize=20)\n",
    "ax3.set_title(\"Q-Learning\",fontsize=20)\n",
    "for ax in [ax1, ax2, ax3]:\n",
    "    ax.plot([2.5, 3.5], [1.5 , 1.5], color='red', linewidth=3)\n",
    "    ax.plot([1.5, 1.5], [0.5 , 1.5], color='red', linewidth=3)\n",
    "    ax.plot([0.5, 0.5], [1.5 , 3.5], color='red', linewidth=3)\n",
    "    ax.plot([0.5, 1.5], [0.5 , 0.5], color='red', linewidth=3)\n",
    "    ax.plot([1.5, 2.5], [2.5 , 2.5], color='red', linewidth=3)\n",
    "    ax.plot([2.5, 2.5], [1.5 , 2.5], color='red', linewidth=3)\n",
    "    ax.plot([2.5, 2.5], [-0.5, 0.5], color='red', linewidth=3)\n",
    "    ax.text(0, -0.2, 'START', ha='center', fontsize=14)\n",
    "    ax.text(3, 2.8, 'GOAL', ha='center', fontsize=14)\n",
    "\n",
    "    # -- reformat size\n",
    "    ax.set_xlim(-0.5, 3.5)\n",
    "    ax.set_ylim(-0.5, 3.5)\n",
    "    # -- describe the state number\n",
    "    s_num = 0\n",
    "    for j in range(4):\n",
    "        for i in range(4):\n",
    "            ax.text(i, j, 's{}'.format(s_num), size=20, ha='center')\n",
    "            s_num += 1\n",
    "\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                    labelbottom=False, right=False, left=False, labelleft=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T06:51:25.293662Z",
     "start_time": "2019-03-12T06:50:07.729965Z"
    }
   },
   "outputs": [],
   "source": [
    "def update(i):\n",
    "    ax1.set_title(\"episode: {}\".format(i+1),fontsize=20)\n",
    "    img1 = ax2.imshow(V_sarsa[i])\n",
    "    img2 = ax3.imshow(V_Qlearning[i])\n",
    "\n",
    "anim = FuncAnimation(fig, update, interval=100 ,frames=len(V_sarsa))\n",
    "anim.save(\"V_transition.mp4\", writer=\"ffmpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maze with Hole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T06:44:34.423766Z",
     "start_time": "2019-03-12T06:44:34.415520Z"
    }
   },
   "outputs": [],
   "source": [
    "def play_maze(Q, pi, epsilon, eta, gamma, update_method=\"q_learning\", hole_flg=False):\n",
    "    # return state_action_history, updated Q function\n",
    "    s = 0\n",
    "    s_a_history = [[0, np.nan]]\n",
    "    # substitute action later\n",
    "    \n",
    "    trial_num  = 0\n",
    "    a_next = get_next_action(s, Q, pi, epsilon)\n",
    "    # selecting action\n",
    "    \n",
    "    while True:\n",
    "        # print(\"current state: {}, next action : {}\".format(s, action))\n",
    "        action = a_next \n",
    "        \n",
    "        trial_num += 1\n",
    "        \n",
    "        s_a_history[-1][1] = action\n",
    "        \n",
    "        s_next = get_s_next(s=s, next_a=action)\n",
    "       \n",
    "        s_a_history.append([s_next, np.nan])\n",
    "        \n",
    "        if s_next == 15:\n",
    "            r = 1\n",
    "            a_next = None\n",
    "        elif s_next == 5 and hole_flg:\n",
    "            r = -0.05\n",
    "            a_next = get_next_action(s_next, Q, pi, epsilon)\n",
    "        else:\n",
    "            r = 0\n",
    "            a_next = get_next_action(s_next, Q, pi, epsilon)\n",
    "        \n",
    "        if update_method == \"sarsa\":\n",
    "            Q = Sarsa(Q, s, action, r, s_next, a_next, eta, gamma)\n",
    "            \n",
    "        elif update_method == \"q_learning\":\n",
    "            Q = update_q_table(Q, s, action, r, s_next, eta, gamma)\n",
    "        \n",
    "        if s_next == 15:\n",
    "            break\n",
    "        else:\n",
    "            s = s_next\n",
    "        \n",
    "    return s_a_history, Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T06:46:46.847931Z",
     "start_time": "2019-03-12T06:46:46.705857Z"
    }
   },
   "outputs": [],
   "source": [
    "# - define the const\n",
    "\n",
    "eta = 0.1   # learning rate\n",
    "GAMMA = 0.9 # discount rate\n",
    "epsilon = 0.5\n",
    "continue_flg = True\n",
    "episode = 1\n",
    "max_episode = 100\n",
    "directions = {'UP'   :  4,\n",
    "              'RIGHT':  1,\n",
    "              'DOWN' : -4,\n",
    "              'LEFT' : -1\n",
    "             }\n",
    "\n",
    "action2col = { act: col for col,act in enumerate(directions) }\n",
    "i, j = pi_0.shape\n",
    "Q = np.random.rand(i, j) * theta * 0.1\n",
    "initial_Q = Q.copy()\n",
    "Q_sarsa = Q.copy()\n",
    "Q_Qlearning = Q.copy()\n",
    "V_sarsa = np.nanmax(Q, axis=1).reshape(1, -1)\n",
    "V_Qlearning = np.nanmax(Q, axis=1).reshape(1, -1)\n",
    "\n",
    "while continue_flg:\n",
    "    \n",
    "    print(\"========== Episode: {} ==========\".format(episode))\n",
    "    epsilon /= 1.1\n",
    "    # more exploration in earlier experices \n",
    "    \n",
    "    if episode > 30:\n",
    "        hole_flg = True\n",
    "    else:\n",
    "        hole_flg = False\n",
    "        \n",
    "    s_a_history_sarsa    , new_Q_sarsa     = play_maze(Q_sarsa, pi_0, epsilon, eta, \n",
    "                                                       GAMMA, update_method=\"sarsa\", hole_flg=hole_flg)\n",
    "    s_a_history_Qlearning, new_Q_Qlearning = play_maze(Q_Qlearning, pi_0, epsilon, eta, \n",
    "                                                       GAMMA,update_method=\"q_learning\", hole_flg=hole_flg)\n",
    "\n",
    "    new_v_sarsa     = np.nanmax(new_Q_sarsa    , axis=1).reshape(1, -1)\n",
    "    new_v_Qlearning = np.nanmax(new_Q_Qlearning, axis=1).reshape(1, -1)\n",
    "    \n",
    "    V_sarsa     = np.append(V_sarsa    , new_v_sarsa, axis=0)\n",
    "    V_Qlearning = np.append(V_Qlearning, new_v_Qlearning, axis=0)\n",
    "    \n",
    "    Q_sarsa     = new_Q_sarsa.copy()\n",
    "    Q_Qlearning = new_Q_Qlearning.copy()\n",
    "    \n",
    "    print(\"Sarsa step size in this trial is {}.\".format(len(s_a_history_sarsa)-1))\n",
    "    print(\"Q-learning step size in this trial is {}.\".format(len(s_a_history_sarsa)-1))\n",
    "    \n",
    "    episode += 1\n",
    "    if episode >= max_episode:\n",
    "        continue_flg = False\n",
    "\n",
    "# - reformat V for visualizing\n",
    "v_16 = np.ones((100,1))\n",
    "V_sarsa = np.concatenate((V_sarsa, v_16), axis=1).reshape(-1, 4, 4)\n",
    "V_Qlearning = np.concatenate((V_Qlearning, v_16), axis=1).reshape(-1, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T06:46:59.520360Z",
     "start_time": "2019-03-12T06:46:59.037945Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(18, 5))\n",
    "\n",
    "ax2.set_title(\"Sarsa\",fontsize=20)\n",
    "ax3.set_title(\"Q-Learning\",fontsize=20)\n",
    "for ax in [ax1, ax2, ax3]:\n",
    "    ax.plot([2.5, 3.5], [1.5 , 1.5], color='red', linewidth=3)\n",
    "    ax.plot([1.5, 1.5], [0.5 , 1.5], color='red', linewidth=3)\n",
    "    ax.plot([0.5, 0.5], [1.5 , 3.5], color='red', linewidth=3)\n",
    "    ax.plot([0.5, 1.5], [0.5 , 0.5], color='red', linewidth=3)\n",
    "    ax.plot([1.5, 2.5], [2.5 , 2.5], color='red', linewidth=3)\n",
    "    ax.plot([2.5, 2.5], [1.5 , 2.5], color='red', linewidth=3)\n",
    "    ax.plot([2.5, 2.5], [-0.5, 0.5], color='red', linewidth=3)\n",
    "    ax.text(1.0, 0.8, 'HOLE', ha='center', fontsize=14)\n",
    "    ax.text(0, -0.2, 'START', ha='center', fontsize=14)\n",
    "    ax.text(3, 2.8, 'GOAL', ha='center', fontsize=14)\n",
    "\n",
    "    # -- reformat size\n",
    "    ax.set_xlim(-0.5, 3.5)\n",
    "    ax.set_ylim(-0.5, 3.5)\n",
    "    # -- describe the state number\n",
    "    s_num = 0\n",
    "    for j in range(4):\n",
    "        for i in range(4):\n",
    "            ax.text(i, j, 's{}'.format(s_num), size=20, ha='center')\n",
    "            s_num += 1\n",
    "\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                    labelbottom=False, right=False, left=False, labelleft=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T06:48:16.456692Z",
     "start_time": "2019-03-12T06:47:00.097839Z"
    }
   },
   "outputs": [],
   "source": [
    "anim = FuncAnimation(fig, update, interval=100 ,frames=len(V_sarsa))\n",
    "anim.save(\"V_transition_with_hole.mp4\", writer=\"ffmpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "209px",
    "left": "1136px",
    "right": "20px",
    "top": "120px",
    "width": "284px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
